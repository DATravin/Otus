# Архетиктурные особенности решения

было поднято 2 Виртуальных машины:

1) первая под Airflow
2) вторая под Mlflow

Так же в решение участвуют 2 бакета. 
1) разварачивается через terraform. Его функция: хранение артефактов Mlflow (именно он используется в качестве backend'а) + туда загружается .py скрипт из репы
2) Второй стационарный "cold". Его функциональность: хранение архива с окружением, который я делал отдельно. А также хранение сохраненных витрин с боевыми данными.

# организация данных

Процесс очистки данных из предыдущих этапов работы занимал довольно продолжительное время. Поэтому у меня на отработано 3 месяца (3 файла), сложенны в виде паркетов на холодное хранилище
Так же для предсказания "плохих" транзакций у меня заранее на базе основных данных расчитаны 2 дополнительные витрины, с фичами по customer_id и terminal_id
В процессе обучения / инференса происходит соединение 3-х витрин по нужным ключам.

(предполагается, что наша модель работает в оффлайне раз в сутки. Поэтому сперва считаются витрины за прошлый день, а после уже происходит скоринг текущего дня)

Для нескольких итераций обучения берется несколько дней в качестве train и один день для test.
Очень важно соблюсти временные рамки. Простой train-test-split здесь не применими и приведет к логическим ошибкам и драматической разнице между качеством на инференсе и при обучении

так как фичей в принциипе не много, данный объем более чем избыточен для модели.

Для того, чтобы интерации отличались, тестовая выборка всегда одинакова. А треновая берет меняется (изначально она одна, но мы берем sample = 0.5 из нее)

# Mlflow

В качестве backend используется кластер Postgree 
В коде есть также модуль для поднятия Mysql. Но с ним запустить не вышло. Но код я оставил на всякий случай.

При создании ВМ мы также:
  накатываем все необходимые библиотеки
  загружаем сертификат для postgree
  объявляем все необходимые переменные
  создаем конфиг для s3
Таким образом после создания остается только в скрине запустить одну команду:

mlflow server --backend-store-uri postgresql://${DB_USER}:${DB_PASS}@${DB_HOST}:${DB_PORT}/${DB_NAME}?sslmode=verify-full --default-artifact-root s3://${S3_BUCKET}/artifacts -h 0.0.0.0 -p 8000




  



